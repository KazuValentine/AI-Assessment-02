{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import models, transforms, datasets\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (confusion_matrix, ConfusionMatrixDisplay, \n",
    "                             classification_report, precision_score, recall_score, f1_score, \n",
    "                             roc_auc_score, average_precision_score, mean_squared_error)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from PIL import Image\n",
    "\n",
    "# Set device: use MPS on Apple Silicon if available, otherwise CPU\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Model Definition: TunedResNet18\n",
    "# -----------------------------------\n",
    "\n",
    "class TunedResNet18(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_size, dropout_rate):\n",
    "        super(TunedResNet18, self).__init__()\n",
    "        # Load pre-trained ResNet18 model\n",
    "        self.resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        # Replace final fc layer with a custom classifier\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, hidden_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Dataset Definition: FaceCroppedDataset\n",
    "# -----------------------------------\n",
    "\n",
    "class FaceCroppedDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.dataset = datasets.ImageFolder(root_dir)\n",
    "        self.transform = transform\n",
    "        self.face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.dataset.samples[idx]\n",
    "        image = cv2.imread(path)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        faces = self.face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "        if len(faces) > 0:\n",
    "            x, y, w, h = faces[0]\n",
    "            face = image[y:y+h, x:x+w]\n",
    "        else:\n",
    "            face = image  # fallback if no face is detected\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "        face = Image.fromarray(face)\n",
    "        if self.transform:\n",
    "            face = self.transform(face)\n",
    "        return face, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Data Transforms and Loaders\n",
    "# -----------------------------------\n",
    "\n",
    "# Define transformation (for both test and cross-validation, we use the same for simplicity)\n",
    "# Training transform with additional augmentation (flipping, rotation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x.convert(\"RGB\")),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),           # Flip images horizontally\n",
    "    transforms.RandomRotation(degrees=15),         # Rotate images up to 15 degrees\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Testing/validation transform (no random augmentation)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x.convert(\"RGB\")),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from: Models/resnet18_fer-2013_best_hs256_drop0.3_lr0.0001_adam.pt\n",
      "Classes: ['angry', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "# Update this path to your facial emotion data directory\n",
    "data_dir = \"FER-2013\" \n",
    "\n",
    "# Load test dataset\n",
    "test_dataset = FaceCroppedDataset(os.path.join(data_dir, \"test\"), transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# For cross-validation, use a subset of training data to save time\n",
    "full_train_dataset = FaceCroppedDataset(os.path.join(data_dir, \"train\"), transform=train_transform)\n",
    "subset_ratio = 0.3  # use 30% of the training data\n",
    "num_train_samples = int(len(full_train_dataset) * subset_ratio)\n",
    "indices = np.random.choice(len(full_train_dataset), num_train_samples, replace=False)\n",
    "cv_dataset = Subset(full_train_dataset, indices)\n",
    "\n",
    "# Extract labels for cross-validation splitting (from the underlying ImageFolder)\n",
    "cv_labels = [full_train_dataset.dataset.samples[i][1] for i in indices]\n",
    "\n",
    "# -----------------------------------\n",
    "# Load Saved Model\n",
    "# -----------------------------------\n",
    "\n",
    "# Define best hyperparameters from the saved model\n",
    "best_hidden_size = 256\n",
    "best_dropout_rate = 0.3\n",
    "num_classes = 6  # \"angry\", \"fear\", \"happy\", \"natural\", \"sad\", \"surprise\"\n",
    "\n",
    "# Specify the model file path\n",
    "model_path = os.path.join(\"Models/resnet18_fer-2013_best_hs256_drop0.3_lr0.0001_adam.pt\")\n",
    "\n",
    "# Instantiate the model and load weights\n",
    "model_fer = TunedResNet18(num_classes=num_classes, hidden_size=best_hidden_size, dropout_rate=best_dropout_rate)\n",
    "model_fer.load_state_dict(torch.load(model_path))\n",
    "model_fer.to(device)\n",
    "print(\"Loaded model from:\", model_path)\n",
    "\n",
    "# Get class names from the training dataset (assuming the folder names correspond to your classes)\n",
    "classes = full_train_dataset.dataset.classes\n",
    "print(\"Classes:\", classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Training Helper Functions\n",
    "# -----------------------------------\n",
    "\n",
    "def train_one_epoch(model, optimizer, criterion, loader, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, targets in loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_model(model, criterion, loader, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc, all_preds, all_targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Fold 1\n",
      "Fold 1 Epoch 1/5: Train Loss: 1.3551, Train Acc: 0.4790, Val Loss: 1.2585, Val Acc: 0.5147\n",
      "Fold 1 Epoch 2/5: Train Loss: 1.2481, Train Acc: 0.5244, Val Loss: 1.4084, Val Acc: 0.4878\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m fold_train_accuracies \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs_cv):\n\u001b[0;32m---> 35\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfold_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_cv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     val_loss, val_acc, _, _ \u001b[38;5;241m=\u001b[39m validate_model(fold_model, criterion, val_loader_cv, device)\n\u001b[1;32m     37\u001b[0m     fold_train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[6], line 17\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, criterion, loader, device)\u001b[0m\n\u001b[1;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 17\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     18\u001b[0m _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (preds \u001b[38;5;241m==\u001b[39m targets)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# Cross-Validation Training\n",
    "# -----------------------------------\n",
    "\n",
    "# Use StratifiedKFold for CV (e.g., 3-fold CV)\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "all_fold_train_losses = []\n",
    "all_fold_train_accuracies = []\n",
    "cv_losses = []\n",
    "cv_accuracies = []\n",
    "num_epochs_cv = 5  # Adjust epochs for CV\n",
    "\n",
    "fold = 0\n",
    "for train_idx, val_idx in kfold.split(np.zeros(len(cv_dataset)), cv_labels):\n",
    "    fold += 1\n",
    "    print(f\"\\nStarting Fold {fold}\")\n",
    "    train_subset = Subset(cv_dataset, train_idx)\n",
    "    val_subset = Subset(cv_dataset, val_idx)\n",
    "    train_loader_cv = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "    val_loader_cv = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    # For each fold, initialize a fresh copy of the model and load saved weights\n",
    "    fold_model = TunedResNet18(num_classes=num_classes, hidden_size=best_hidden_size, dropout_rate=best_dropout_rate)\n",
    "    fold_model.load_state_dict(torch.load(model_path))\n",
    "    fold_model.to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(fold_model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    fold_train_losses = []\n",
    "    fold_train_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs_cv):\n",
    "        train_loss, train_acc = train_one_epoch(fold_model, optimizer, criterion, train_loader_cv, device)\n",
    "        val_loss, val_acc, _, _ = validate_model(fold_model, criterion, val_loader_cv, device)\n",
    "        fold_train_losses.append(train_loss)\n",
    "        fold_train_accuracies.append(train_acc)\n",
    "        print(f\"Fold {fold} Epoch {epoch+1}/{num_epochs_cv}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    all_fold_train_losses.append(fold_train_losses)\n",
    "    all_fold_train_accuracies.append(fold_train_accuracies)\n",
    "    cv_losses.append(fold_train_losses[-1])\n",
    "    cv_accuracies.append(fold_train_accuracies[-1])\n",
    "\n",
    "print(\"\\nCross Validation Results:\")\n",
    "print(\"Average Final Train Loss:\", np.mean([losses[-1] for losses in all_fold_train_losses]))\n",
    "print(\"Average Final Train Accuracy:\", np.mean([accs[-1] for accs in all_fold_train_accuracies]))\n",
    "\n",
    "# Plot average training loss and accuracy across folds\n",
    "epochs_range = range(1, num_epochs_cv+1)\n",
    "avg_train_losses = np.mean(all_fold_train_losses, axis=0)\n",
    "avg_train_accuracies = np.mean(all_fold_train_accuracies, axis=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs_range, avg_train_losses, marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Average Training Loss Across CV Folds')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs_range, avg_train_accuracies, marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.title('Average Training Accuracy Across CV Folds')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model_fer.parameters(), lr=0.0001)\n",
    "\n",
    "num_epochs = 5 \n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "print(\"Starting Training on FER-2013...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model_fer, train_loader_cv, optimizer, criterion, device)\n",
    "    # If you'd like, you can run validation here on a separate validation split\n",
    "    # but for simplicity, we'll only train on the entire train set.\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]: Train Loss = {train_loss:.4f}, Train Acc = {train_acc:.4f}\")\n",
    "\n",
    "print(\"Training Complete.\")\n",
    "\n",
    "# Plot the training loss and accuracy\n",
    "epochs_range = range(1, num_epochs+1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs_range, train_losses, marker='o')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.title(\"Training Loss over Epochs\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs_range, train_accuracies, marker='o')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Accuracy\")\n",
    "plt.title(\"Training Accuracy over Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Final Evaluation on Test Data\n",
    "# -----------------------------------\n",
    "\n",
    "model_fer.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "all_probs = []  # For probability outputs\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model_fer(inputs)\n",
    "        probs = nn.functional.softmax(outputs, dim=1)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(targets.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "# Plot confusion matrix with green colormap\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "disp.plot(cmap='Greens')\n",
    "plt.title(\"Confusion Matrix (Green)\")\n",
    "plt.show()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "precision_macro = precision_score(all_targets, all_preds, average='macro')\n",
    "recall_macro = recall_score(all_targets, all_preds, average='macro')\n",
    "f1_macro = f1_score(all_targets, all_preds, average='macro')\n",
    "precision_weighted = precision_score(all_targets, all_preds, average='weighted')\n",
    "recall_weighted = recall_score(all_targets, all_preds, average='weighted')\n",
    "f1_weighted = f1_score(all_targets, all_preds, average='weighted')\n",
    "\n",
    "# For ROC-AUC and PR-AUC, binarize the targets\n",
    "all_targets_bin = label_binarize(all_targets, classes=range(num_classes))\n",
    "roc_auc = roc_auc_score(all_targets_bin, all_probs, average='macro', multi_class='ovr')\n",
    "pr_auc = average_precision_score(all_targets_bin, all_probs, average='macro')\n",
    "\n",
    "mse = mean_squared_error(all_targets, all_preds)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "print(f\"F1 Score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"Precision (Weighted): {precision_weighted:.4f}\")\n",
    "print(f\"Recall (Weighted): {recall_weighted:.4f}\")\n",
    "print(f\"F1 Score (Weighted): {f1_weighted:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "print(f\"PR-AUC: {pr_auc:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_targets, all_preds, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Load Saved Model RAF\n",
    "# -----------------------------------\n",
    "\n",
    "# Define best hyperparameters from the saved model\n",
    "best_hidden_size = 256\n",
    "best_dropout_rate = 0.3\n",
    "num_classes = 6  # \"angry\", \"fear\", \"happy\", \"natural\", \"sad\", \"surprise\"\n",
    "\n",
    "# Specify the model file path\n",
    "model_path = os.path.join(\"Models/resnet18_best_RAF-DB_256_drop0.3_lr0.0001_adam.pt\")\n",
    "\n",
    "# Instantiate the model and load weights\n",
    "model_raf = TunedResNet18(num_classes=num_classes, hidden_size=best_hidden_size, dropout_rate=best_dropout_rate)\n",
    "model_raf.load_state_dict(torch.load(model_path))\n",
    "model_raf.to(device)\n",
    "print(\"Loaded model from:\", model_path)\n",
    "\n",
    "# Get class names from the training dataset (assuming the folder names correspond to your classes)\n",
    "classes = full_train_dataset.dataset.classes\n",
    "print(\"Classes:\", classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Cross-Validation Training\n",
    "# -----------------------------------\n",
    "\n",
    "# Use StratifiedKFold for CV (e.g., 3-fold CV)\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "all_fold_train_losses = []\n",
    "all_fold_train_accuracies = []\n",
    "cv_losses = []\n",
    "cv_accuracies = []\n",
    "num_epochs_cv = 5  # Adjust epochs for CV\n",
    "\n",
    "fold = 0\n",
    "for train_idx, val_idx in kfold.split(np.zeros(len(cv_dataset)), cv_labels):\n",
    "    fold += 1\n",
    "    print(f\"\\nStarting Fold {fold}\")\n",
    "    train_subset = Subset(cv_dataset, train_idx)\n",
    "    val_subset = Subset(cv_dataset, val_idx)\n",
    "    train_loader_cv = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "    val_loader_cv = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    # For each fold, initialize a fresh copy of the model and load saved weights\n",
    "    fold_model = TunedResNet18(num_classes=num_classes, hidden_size=best_hidden_size, dropout_rate=best_dropout_rate)\n",
    "    fold_model.load_state_dict(torch.load(model_path))\n",
    "    fold_model.to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(fold_model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    fold_train_losses = []\n",
    "    fold_train_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs_cv):\n",
    "        train_loss, train_acc = train_one_epoch(fold_model, optimizer, criterion, train_loader_cv, device)\n",
    "        val_loss, val_acc, _, _ = validate_model(fold_model, criterion, val_loader_cv, device)\n",
    "        fold_train_losses.append(train_loss)\n",
    "        fold_train_accuracies.append(train_acc)\n",
    "        print(f\"Fold {fold} Epoch {epoch+1}/{num_epochs_cv}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    all_fold_train_losses.append(fold_train_losses)\n",
    "    all_fold_train_accuracies.append(fold_train_accuracies)\n",
    "    cv_losses.append(fold_train_losses[-1])\n",
    "    cv_accuracies.append(fold_train_accuracies[-1])\n",
    "\n",
    "print(\"\\nCross Validation Results:\")\n",
    "print(\"Average Final Train Loss:\", np.mean([losses[-1] for losses in all_fold_train_losses]))\n",
    "print(\"Average Final Train Accuracy:\", np.mean([accs[-1] for accs in all_fold_train_accuracies]))\n",
    "\n",
    "# Plot average training loss and accuracy across folds\n",
    "epochs_range = range(1, num_epochs_cv+1)\n",
    "avg_train_losses = np.mean(all_fold_train_losses, axis=0)\n",
    "avg_train_accuracies = np.mean(all_fold_train_accuracies, axis=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs_range, avg_train_losses, marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Average Training Loss Across CV Folds')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs_range, avg_train_accuracies, marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.title('Average Training Accuracy Across CV Folds')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model_fer.parameters(), lr=0.0001)\n",
    "\n",
    "num_epochs = 5 \n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "print(\"Starting Training on RAF-DB...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model_raf, train_loader_cv, optimizer, criterion, device)\n",
    "    # If you'd like, you can run validation here on a separate validation split\n",
    "    # but for simplicity, we'll only train on the entire train set.\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]: Train Loss = {train_loss:.4f}, Train Acc = {train_acc:.4f}\")\n",
    "\n",
    "print(\"Training Complete.\")\n",
    "\n",
    "# Plot the training loss and accuracy\n",
    "epochs_range = range(1, num_epochs+1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs_range, train_losses, marker='o')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.title(\"Training Loss over Epochs\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs_range, train_accuracies, marker='o')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Accuracy\")\n",
    "plt.title(\"Training Accuracy over Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Final Evaluation on Test Data\n",
    "# -----------------------------------\n",
    "\n",
    "model_raf.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "all_probs = []  # For probability outputs\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model_raf(inputs)\n",
    "        probs = nn.functional.softmax(outputs, dim=1)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(targets.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "# Plot confusion matrix with green colormap\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "disp.plot(cmap='Greens')\n",
    "plt.title(\"Confusion Matrix (Green)\")\n",
    "plt.show()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "precision_macro = precision_score(all_targets, all_preds, average='macro')\n",
    "recall_macro = recall_score(all_targets, all_preds, average='macro')\n",
    "f1_macro = f1_score(all_targets, all_preds, average='macro')\n",
    "precision_weighted = precision_score(all_targets, all_preds, average='weighted')\n",
    "recall_weighted = recall_score(all_targets, all_preds, average='weighted')\n",
    "f1_weighted = f1_score(all_targets, all_preds, average='weighted')\n",
    "\n",
    "# For ROC-AUC and PR-AUC, binarize the targets\n",
    "all_targets_bin = label_binarize(all_targets, classes=range(num_classes))\n",
    "roc_auc = roc_auc_score(all_targets_bin, all_probs, average='macro', multi_class='ovr')\n",
    "pr_auc = average_precision_score(all_targets_bin, all_probs, average='macro')\n",
    "\n",
    "mse = mean_squared_error(all_targets, all_preds)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "print(f\"F1 Score (Macro): {f1_macro:.4f}\")\n",
    "print(f\"Precision (Weighted): {precision_weighted:.4f}\")\n",
    "print(f\"Recall (Weighted): {recall_weighted:.4f}\")\n",
    "print(f\"F1 Score (Weighted): {f1_weighted:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "print(f\"PR-AUC: {pr_auc:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_targets, all_preds, target_names=classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArtificialIntelligence-Assignment-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
